{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "1f9fc28b",
   "metadata": {},
   "source": [
    "### DataFrames y Datasets\n",
    "Los **DataFrames** y los **Datasets** son colecciones (distribuidas) tipo tabla con filas y columnas bien definidas. Cada columna debe tener el mismo numero de filas que el resto de columnas (introduciendo nulos cuando no hay valor).   \n",
    "**Esquemas:** Definen el nombre de la columna y el tipo de datos que contiene. Puedes crear el esquema manualmente o leerlo a a partir de los datos.   \n",
    "\n",
    "**Diferencias entre DataFrames y Datasets**   \n",
    "- DataFrames: \"untyped\" data. Spark mantiene la estructura completa y solo comprueba si los tipos son los mismos que los especificados en tiempo de ejecucion (runtime).       \n",
    "- Datasets: \"typed\" data. Spark comprueba si los tipos de datos son los mismos que los especificados en tiempo de computaci√≥n \"compile time\". Solo existen en Scala y Java.     \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5c7c8d55",
   "metadata": {},
   "source": [
    "### SCALA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "3742785f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Intitializing Scala interpreter ..."
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "Spark Web UI available at http://EM2021002836.bosonit.local:4043\n",
       "SparkContext available as 'sc' (version = 3.1.1, master = local[*], app id = local-1622800395991)\n",
       "SparkSession available as 'spark'\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "df: org.apache.spark.sql.DataFrame = [number: bigint]\r\n",
       "res0: org.apache.spark.sql.DataFrame = [(number + 10): bigint]\r\n"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val df = spark.range(500).toDF(\"number\")\n",
    "df.select(df.col(\"number\") + 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b53658e2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "res1: Array[org.apache.spark.sql.Row] = Array([0], [1])\r\n"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "//Crear una fila\n",
    "spark.range(2).toDF().collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "4fc4f051",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "import org.apache.spark.sql.types._\r\n",
       "b: org.apache.spark.sql.types.ByteType.type = ByteType\r\n"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "//Tipos de datos en Scala: pag 60\n",
    "import org.apache.spark.sql.types._\n",
    "val b = ByteType"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f8b0d203",
   "metadata": {},
   "source": [
    "### PYTHON"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a055e265",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DataFrame[(number + 10): bigint]"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = spark.range(500).toDF(\"number\")\n",
    "df.select(df[\"number\"] + 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a3f4c0f7",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Row(id=0), Row(id=1)]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "##Crear una columna\n",
    "spark.range(2).collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "8ad8741e",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Tipos de datos en Python: pag 59\n",
    "from pyspark.sql.types import *\n",
    "b = ByteType()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "spylon-kernel",
   "language": "scala",
   "name": "spylon-kernel"
  },
  "language_info": {
   "codemirror_mode": "text/x-scala",
   "file_extension": ".scala",
   "help_links": [
    {
     "text": "MetaKernel Magics",
     "url": "https://metakernel.readthedocs.io/en/latest/source/README.html"
    }
   ],
   "mimetype": "text/x-scala",
   "name": "scala",
   "pygments_lexer": "scala",
   "version": "0.4.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
